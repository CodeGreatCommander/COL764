hidden_layer_sizes: [200, 200]
activation: 'relu'
solver: 'adam'
learning_rate_init: 0.015186219938729926
max_iter: 500
random_state: 0
alpha: 0.0407761064878215